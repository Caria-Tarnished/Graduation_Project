# QLoRA å¾®è°ƒ Deepseek-7B - Colab è®­ç»ƒå•å…ƒæ ¼

## è¯´æ˜
- æœ¬æ–‡ä»¶åŒ…å«åœ¨ Google Colab ä¸Šå¾®è°ƒ Deepseek-7B çš„å®Œæ•´æµç¨‹
- éœ€è¦ T4 GPUï¼ˆå…è´¹ç‰ˆå³å¯ï¼‰
- è®­ç»ƒæ—¶é—´ï¼šçº¦ 2-4 å°æ—¶ï¼ˆå–å†³äºæ•°æ®é‡ï¼‰
- è¾“å‡ºï¼šLoRA Adapter æƒé‡æ–‡ä»¶ï¼ˆçº¦ 30-50 MBï¼‰

---

## å•å…ƒæ ¼ 1ï¼šç¯å¢ƒå‡†å¤‡ä¸æŒ‚è½½ Drive

```python
# 1.1 æ£€æŸ¥ GPU
!nvidia-smi

# 1.2 æŒ‚è½½ Google Drive
from google.colab import drive
drive.mount('/content/drive')

# 1.3 åˆ‡æ¢åˆ°é¡¹ç›®ç›®å½•
%cd /content/drive/MyDrive/Graduation_Project

# 1.4 å®‰è£…ä¾èµ–
!pip install -q transformers==4.36.0
!pip install -q peft==0.7.1
!pip install -q bitsandbytes==0.41.3
!pip install -q accelerate==0.25.0
!pip install -q datasets==2.16.0
!pip install -q trl==0.7.4

print("\nâœ“ ç¯å¢ƒå‡†å¤‡å®Œæˆ")
```

---

## å•å…ƒæ ¼ 2ï¼šå…‹éš†/æ›´æ–°ä»£ç ä»“åº“

```python
import os

# æ£€æŸ¥æ˜¯å¦å·²å…‹éš†
if not os.path.exists('/content/Graduation_Project'):
    print("å…‹éš†ä»£ç ä»“åº“...")
    !git clone https://github.com/YOUR_USERNAME/Graduation_Project.git /content/Graduation_Project
else:
    print("æ›´æ–°ä»£ç ä»“åº“...")
    %cd /content/Graduation_Project
    !git pull

%cd /content/Graduation_Project

print("\nâœ“ ä»£ç ä»“åº“å‡†å¤‡å®Œæˆ")
```

---

## å•å…ƒæ ¼ 3ï¼šç”ŸæˆæŒ‡ä»¤é›†æ•°æ®

```python
# 3.1 æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å­˜åœ¨
import os
from pathlib import Path

db_path = Path('finance_analysis.db')

if not db_path.exists():
    print("âš  æ•°æ®åº“ä¸å­˜åœ¨ï¼Œå°†ä» Drive å¤åˆ¶...")
    !cp /content/drive/MyDrive/Graduation_Project/finance_analysis.db .
    print("âœ“ æ•°æ®åº“å¤åˆ¶å®Œæˆ")
else:
    print("âœ“ æ•°æ®åº“å·²å­˜åœ¨")

# 3.2 ç”ŸæˆæŒ‡ä»¤é›†
print("\nç”ŸæˆæŒ‡ä»¤é›†æ•°æ®...")
!python scripts/qlora/build_instruction_dataset.py \
    --db finance_analysis.db \
    --output data/qlora/instructions.jsonl \
    --num_samples 300

# 3.3 æŸ¥çœ‹ç”Ÿæˆçš„æ•°æ®
print("\næŸ¥çœ‹å‰ 3 æ¡æŒ‡ä»¤ï¼š")
import json

with open('data/qlora/instructions.jsonl', 'r', encoding='utf-8') as f:
    for i, line in enumerate(f):
        if i >= 3:
            break
        data = json.loads(line)
        print(f"\n--- æŒ‡ä»¤ {i+1} ---")
        print(f"Instruction: {data['instruction']}")
        print(f"Input: {data['input'][:80]}...")
        print(f"Output: {data['output'][:100]}...")

print("\nâœ“ æŒ‡ä»¤é›†ç”Ÿæˆå®Œæˆ")
```

---

## å•å…ƒæ ¼ 4ï¼šå¼€å§‹ QLoRA å¾®è°ƒï¼ˆä¸»è®­ç»ƒï¼‰

```python
# 4.1 è®¾ç½®è¾“å‡ºç›®å½•
output_dir = '/content/drive/MyDrive/Graduation_Project/qlora_output'

# 4.2 å¼€å§‹è®­ç»ƒ
print("="*60)
print("å¼€å§‹ QLoRA å¾®è°ƒ...")
print("="*60)
print("é¢„è®¡è®­ç»ƒæ—¶é—´ï¼š2-4 å°æ—¶")
print("è¯·ä¿æŒ Colab é¡µé¢æ‰“å¼€ï¼Œé¿å…æ–­å¼€è¿æ¥")
print("="*60)

!python scripts/qlora/train_qlora.py \
    --model_name deepseek-ai/deepseek-llm-7b-chat \
    --data_path data/qlora/instructions.jsonl \
    --output_dir {output_dir} \
    --num_epochs 3 \
    --batch_size 4 \
    --learning_rate 2e-4 \
    --max_length 512 \
    --lora_r 8 \
    --lora_alpha 16 \
    --lora_dropout 0.05

print("\nâœ“ è®­ç»ƒå®Œæˆ")
```

---

## å•å…ƒæ ¼ 5ï¼šéªŒè¯è®­ç»ƒç»“æœ

```python
import os
from pathlib import Path
import json

output_dir = Path('/content/drive/MyDrive/Graduation_Project/qlora_output')

print("="*60)
print("è®­ç»ƒç»“æœéªŒè¯")
print("="*60)

# 5.1 æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
print("\n1. æ£€æŸ¥è¾“å‡ºæ–‡ä»¶ï¼š")
required_files = [
    'adapter_model.bin',
    'adapter_config.json',
    'training_info.json'
]

for file in required_files:
    file_path = output_dir / file
    if file_path.exists():
        size_mb = file_path.stat().st_size / (1024 * 1024)
        print(f"   âœ“ {file} ({size_mb:.2f} MB)")
    else:
        print(f"   âœ— {file} (ä¸å­˜åœ¨)")

# 5.2 è¯»å–è®­ç»ƒä¿¡æ¯
print("\n2. è®­ç»ƒä¿¡æ¯ï¼š")
info_path = output_dir / 'training_info.json'
if info_path.exists():
    with open(info_path, 'r', encoding='utf-8') as f:
        info = json.load(f)
    
    print(f"   æ¨¡å‹: {info['model_name']}")
    print(f"   è®­ç»ƒè½®æ•°: {info['num_epochs']}")
    print(f"   æ ·æœ¬æ•°é‡: {info['num_samples']}")
    print(f"   å­¦ä¹ ç‡: {info['learning_rate']}")
    print(f"   LoRA rank: {info['lora_r']}")
    print(f"   å®Œæˆæ—¶é—´: {info['timestamp']}")

# 5.3 è®¡ç®—æ€»å¤§å°
print("\n3. è¾“å‡ºç›®å½•æ€»å¤§å°ï¼š")
total_size = sum(f.stat().st_size for f in output_dir.rglob('*') if f.is_file())
print(f"   {total_size / (1024 * 1024):.2f} MB")

print("\n" + "="*60)
print("âœ“ éªŒè¯å®Œæˆ")
print("="*60)
```

---

## å•å…ƒæ ¼ 6ï¼šæµ‹è¯•å¾®è°ƒåçš„æ¨¡å‹ï¼ˆå¯é€‰ï¼‰

```python
# 6.1 åŠ è½½å¾®è°ƒåçš„æ¨¡å‹
print("åŠ è½½å¾®è°ƒåçš„æ¨¡å‹...")

import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel

# åŠ è½½åŸºç¡€æ¨¡å‹
base_model_name = "deepseek-ai/deepseek-llm-7b-chat"
model = AutoModelForCausalLM.from_pretrained(
    base_model_name,
    load_in_4bit=True,
    torch_dtype=torch.float16,
    device_map='auto',
    trust_remote_code=True
)

# åŠ è½½ LoRA æƒé‡
output_dir = '/content/drive/MyDrive/Graduation_Project/qlora_output'
model = PeftModel.from_pretrained(model, output_dir)

# åŠ è½½ tokenizer
tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)

print("âœ“ æ¨¡å‹åŠ è½½å®Œæˆ")

# 6.2 æµ‹è¯•æ¨ç†
print("\næµ‹è¯•æ¨ç†...")

test_cases = [
    {
        "instruction": "åˆ†æä»¥ä¸‹è´¢ç»å¿«è®¯å¯¹å¸‚åœºçš„å½±å“",
        "input": "ç¾è”å‚¨å®£å¸ƒåŠ æ¯25ä¸ªåŸºç‚¹"
    },
    {
        "instruction": "è§£é‡Šä»€ä¹ˆæ˜¯é¢„æœŸå…‘ç°",
        "input": "å¸‚åœºå‰æœŸå·²ç»å¤§æ¶¨ï¼Œåˆ©å¥½æ¶ˆæ¯å‘å¸ƒååè€Œä¸‹è·Œï¼Œè¿™æ˜¯ä¸ºä»€ä¹ˆï¼Ÿ"
    }
]

for i, test in enumerate(test_cases, 1):
    print(f"\n--- æµ‹è¯•æ¡ˆä¾‹ {i} ---")
    print(f"Instruction: {test['instruction']}")
    print(f"Input: {test['input']}")
    
    # æ„å»º prompt
    prompt = f"User: {test['instruction']}\n{test['input']}\n\nAssistant:"
    
    # Tokenize
    inputs = tokenizer(prompt, return_tensors='pt').to(model.device)
    
    # ç”Ÿæˆ
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=200,
            temperature=0.7,
            top_p=0.9,
            do_sample=True
        )
    
    # è§£ç 
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    
    # æå– Assistant çš„å›å¤
    if "Assistant:" in response:
        response = response.split("Assistant:")[-1].strip()
    
    print(f"Output: {response}")

print("\nâœ“ æµ‹è¯•å®Œæˆ")
```

---

## å•å…ƒæ ¼ 7ï¼šä¸‹è½½æƒé‡æ–‡ä»¶åˆ°æœ¬åœ°ï¼ˆå¯é€‰ï¼‰

```python
# å¦‚æœéœ€è¦ä¸‹è½½åˆ°æœ¬åœ°ç”µè„‘ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç 

from google.colab import files

# ä¸‹è½½ LoRA æƒé‡
output_dir = '/content/drive/MyDrive/Graduation_Project/qlora_output'

print("å‡†å¤‡ä¸‹è½½æ–‡ä»¶...")
print("æ³¨æ„ï¼šæ–‡ä»¶è¾ƒå¤§ï¼Œä¸‹è½½å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ")

# æ‰“åŒ…ä¸º zip
!cd {output_dir} && zip -r qlora_weights.zip adapter_model.bin adapter_config.json training_info.json

# ä¸‹è½½
files.download(f'{output_dir}/qlora_weights.zip')

print("âœ“ ä¸‹è½½å®Œæˆ")
```

---

## è®­ç»ƒå‚æ•°è¯´æ˜

### æ¨¡å‹å‚æ•°
- `model_name`: deepseek-ai/deepseek-llm-7b-chatï¼ˆDeepseek 7B å¯¹è¯æ¨¡å‹ï¼‰
- `data_path`: æŒ‡ä»¤é›†æ•°æ®è·¯å¾„
- `output_dir`: è¾“å‡ºç›®å½•ï¼ˆä¿å­˜åˆ° Driveï¼‰

### è®­ç»ƒå‚æ•°
- `num_epochs`: 3ï¼ˆè®­ç»ƒè½®æ•°ï¼Œå¯æ ¹æ®æ•ˆæœè°ƒæ•´ï¼‰
- `batch_size`: 4ï¼ˆæ‰¹å¤§å°ï¼ŒT4 GPU å¯æ”¯æŒï¼‰
- `learning_rate`: 2e-4ï¼ˆå­¦ä¹ ç‡ï¼‰
- `max_length`: 512ï¼ˆæœ€å¤§åºåˆ—é•¿åº¦ï¼‰

### LoRA å‚æ•°
- `lora_r`: 8ï¼ˆLoRA rankï¼Œæ§åˆ¶å‚æ•°é‡ï¼‰
- `lora_alpha`: 16ï¼ˆLoRA alphaï¼Œç¼©æ”¾å› å­ï¼‰
- `lora_dropout`: 0.05ï¼ˆDropout æ¯”ä¾‹ï¼‰

### é¢„æœŸç»“æœ
- è®­ç»ƒæ—¶é—´ï¼š2-4 å°æ—¶ï¼ˆ300 æ¡æ ·æœ¬ï¼Œ3 epochsï¼‰
- è¾“å‡ºæ–‡ä»¶å¤§å°ï¼šçº¦ 30-50 MB
- å¯è®­ç»ƒå‚æ•°æ¯”ä¾‹ï¼šçº¦ 0.1-0.2%ï¼ˆç›¸æ¯”å®Œæ•´æ¨¡å‹ï¼‰

---

## å¸¸è§é—®é¢˜

### Q1: è®­ç»ƒè¿‡ç¨‹ä¸­æ–­å¼€è¿æ¥æ€ä¹ˆåŠï¼Ÿ
A: è®­ç»ƒä¼šè‡ªåŠ¨ä¿å­˜ checkpointï¼Œå¯ä»¥ä»æœ€è¿‘çš„ checkpoint ç»§ç»­è®­ç»ƒã€‚å»ºè®®ä½¿ç”¨ Colab Pro æˆ–ä¿æŒé¡µé¢æ´»è·ƒã€‚

### Q2: æ˜¾å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ
A: å‡å° `batch_size`ï¼ˆå¦‚æ”¹ä¸º 2ï¼‰æˆ– `max_length`ï¼ˆå¦‚æ”¹ä¸º 256ï¼‰ã€‚

### Q3: å¦‚ä½•è¯„ä¼°å¾®è°ƒæ•ˆæœï¼Ÿ
A: ä½¿ç”¨å•å…ƒæ ¼ 6 è¿›è¡Œæµ‹è¯•ï¼Œå¯¹æ¯”å¾®è°ƒå‰åçš„è¾“å‡ºè´¨é‡ã€‚

### Q4: å¦‚ä½•åœ¨æœ¬åœ°ä½¿ç”¨å¾®è°ƒåçš„æ¨¡å‹ï¼Ÿ
A: ä¸‹è½½ LoRA æƒé‡æ–‡ä»¶ï¼Œä½¿ç”¨ PEFT åº“åŠ è½½ï¼ˆå‚è€ƒå•å…ƒæ ¼ 6 çš„ä»£ç ï¼‰ã€‚

---

## ä¸‹ä¸€æ­¥

1. **æµ‹è¯•å¾®è°ƒæ•ˆæœ**ï¼šè¿è¡Œå•å…ƒæ ¼ 6ï¼Œæµ‹è¯•æ¨¡å‹è¾“å‡º
2. **é›†æˆåˆ° Agent**ï¼šå°† LoRA æƒé‡é›†æˆåˆ°æœ¬åœ° Agent ç³»ç»Ÿ
3. **ç­”è¾©å‡†å¤‡**ï¼šå‡†å¤‡è®­ç»ƒæ—¥å¿—ã€Loss æ›²çº¿æˆªå›¾

---

**ç¥è®­ç»ƒé¡ºåˆ©ï¼** ğŸ“
