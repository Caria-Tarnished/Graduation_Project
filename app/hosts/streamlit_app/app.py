# -*- coding: utf-8 -*-
"""
Streamlit ä¸»å…¥å£

è´¢ç»åˆ†æ Agent ç³»ç»Ÿ - ç­”è¾©æ¼”ç¤ºç‰ˆ

åŠŸèƒ½ï¼š
- èŠå¤©é¡µé¢ï¼šå¿«è®¯åˆ†æå’Œè´¢æŠ¥é—®ç­”
- K çº¿å›¾è¡¨é¡µé¢ï¼šå¯è§†åŒ– + äº‹ä»¶æ ‡æ³¨
- è´¢æŠ¥æ£€ç´¢é¡µé¢ï¼šRAG æ£€ç´¢å±•ç¤º

å¯åŠ¨å‘½ä»¤ï¼š
    streamlit run app/hosts/streamlit_app/app.py
"""
import streamlit as st
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))


# é¡µé¢é…ç½®
st.set_page_config(
    page_title="è´¢ç»åˆ†æ Agent",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)


def main():
    """ä¸»å‡½æ•°"""
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.title("ğŸ“Š è´¢ç»åˆ†æ Agent")
        st.markdown("---")
        
        st.markdown("""
        ### åŠŸèƒ½å¯¼èˆª
        
        - **ğŸ’¬ èŠå¤©**: å¿«è®¯åˆ†æå’Œè´¢æŠ¥é—®ç­”
        - **ğŸ“ˆ K çº¿å›¾è¡¨**: å¯è§†åŒ– + äº‹ä»¶æ ‡æ³¨
        - **ğŸ“„ è´¢æŠ¥æ£€ç´¢**: RAG æ£€ç´¢å±•ç¤º
        
        ### ç³»ç»ŸçŠ¶æ€
        """)
        
        # æ£€æŸ¥å¼•æ“çŠ¶æ€
        engine_status = check_engine_status()
        
        if engine_status['sentiment_engine']:
            st.success("âœ“ æƒ…æ„Ÿåˆ†æå¼•æ“")
        else:
            st.warning("âš  æƒ…æ„Ÿåˆ†æå¼•æ“æœªåŠ è½½")
        
        if engine_status['rag_engine']:
            st.success("âœ“ RAG æ£€ç´¢å¼•æ“")
        else:
            st.warning("âš  RAG æ£€ç´¢å¼•æ“æœªåŠ è½½")
        
        if engine_status['llm_client']:
            st.success("âœ“ LLM å®¢æˆ·ç«¯")
        else:
            st.warning("âš  LLM å®¢æˆ·ç«¯æœªé…ç½®")
        
        st.markdown("---")
        st.markdown("""
        ### å…³äº
        
        **è´¢ç»åˆ†æ Agent ç³»ç»Ÿ**
        
        åŸºäºæ··åˆ NLP æ¨¡å‹çš„è´¢ç»åˆ†æç³»ç»Ÿï¼Œé‡‡ç”¨åŒå¼•æ“æ¶æ„ï¼š
        - Engine A: æƒ…æ„Ÿåˆ†ç±»ï¼ˆBERT + è§„åˆ™å¼•æ“ï¼‰
        - Engine B: RAG æ£€ç´¢ï¼ˆè´¢æŠ¥é—®ç­”ï¼‰
        
        **æŠ€æœ¯æ ˆ**
        - BERT: æƒ…æ„Ÿåˆ†ç±»
        - Chroma: å‘é‡æ£€ç´¢
        - Deepseek: LLM æ€»ç»“
        - Streamlit: UI ç•Œé¢
        """)
    
    # ä¸»é¡µé¢
    st.title("ğŸ’¬ è´¢ç»åˆ†æ Agent - èŠå¤©ç•Œé¢")
    
    st.markdown("""
    æ¬¢è¿ä½¿ç”¨è´¢ç»åˆ†æ Agentï¼æˆ‘å¯ä»¥å¸®åŠ©æ‚¨ï¼š
    
    1. **åˆ†æè´¢ç»å¿«è®¯**ï¼šè¾“å…¥æ–°é—»å†…å®¹ï¼Œæˆ‘ä¼šåˆ†æå…¶å¯¹å¸‚åœºçš„å½±å“
    2. **å›ç­”è´¢æŠ¥é—®é¢˜**ï¼šè¯¢é—®è´¢æŠ¥ç›¸å…³é—®é¢˜ï¼Œæˆ‘ä¼šä»è´¢æŠ¥ä¸­æ£€ç´¢ç­”æ¡ˆ
    
    è¯·åœ¨ä¸‹æ–¹è¾“å…¥æ‚¨çš„é—®é¢˜ï¼š
    """)
    
    # åˆå§‹åŒ– Agentï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
    agent = initialize_agent()
    
    # èŠå¤©ç•Œé¢
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    # æ˜¾ç¤ºå†å²æ¶ˆæ¯
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # ç”¨æˆ·è¾“å…¥
    if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # ç”Ÿæˆå›å¤
        with st.chat_message("assistant"):
            with st.spinner("æ­£åœ¨åˆ†æ..."):
                response = process_user_query(prompt, agent)
                st.markdown(response["summary"])
                
                # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
                with st.expander("ğŸ“Š åˆ†æè¯¦æƒ…"):
                    if response.get("sentiment"):
                        st.markdown(f"**æƒ…æ„Ÿåˆ†æ**: {response['sentiment']}")
                    
                    if response.get("citations"):
                        st.markdown(f"**å¼•ç”¨æ•°é‡**: {len(response['citations'])} æ¡")
                    
                    if response.get("tool_trace"):
                        st.markdown("**å·¥å…·è°ƒç”¨è¿½è¸ª**:")
                        for trace in response["tool_trace"]:
                            status = "âœ“" if trace["ok"] else "âœ—"
                            st.text(f"{status} {trace['name']} ({trace['elapsed_ms']}ms)")
        
        # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯
        st.session_state.messages.append({"role": "assistant", "content": response["summary"]})


@st.cache_resource
def initialize_agent():
    """
    åˆå§‹åŒ– Agent ç³»ç»Ÿï¼ˆä½¿ç”¨ç¼“å­˜ï¼Œåªæ‰§è¡Œä¸€æ¬¡ï¼‰
    
    Returns:
        Agent å®ä¾‹æˆ– None
    """
    try:
        import os
        
        # åŠ¨æ€å¯¼å…¥æ¨¡å—ï¼ˆé¿å…è·¯å¾„é—®é¢˜ï¼‰
        import importlib.util
        
        # åŠ è½½ Agent æ¨¡å—
        agent_module_path = project_root / "app" / "core" / "orchestrator" / "agent.py"
        spec = importlib.util.spec_from_file_location("agent", agent_module_path)
        agent_module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(agent_module)
        Agent = agent_module.Agent
        
        # å°è¯•åŠ è½½æ‰€æœ‰å¼•æ“
        sentiment_engine = None
        rag_engine = None
        rule_engine = None
        llm_client = None
        
        # 1. åŠ è½½æƒ…æ„Ÿåˆ†æå¼•æ“ï¼ˆEngine Aï¼‰
        try:
            sentiment_module_path = project_root / "app" / "services" / "sentiment_analyzer.py"
            spec = importlib.util.spec_from_file_location("sentiment_analyzer", sentiment_module_path)
            sentiment_module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(sentiment_module)
            SentimentAnalyzer = sentiment_module.SentimentAnalyzer
            
            bert_path = project_root / "models" / "bert_3cls" / "best"
            if bert_path.exists():
                sentiment_engine = SentimentAnalyzer(model_path=str(bert_path))
                st.success("âœ“ æƒ…æ„Ÿåˆ†æå¼•æ“åŠ è½½æˆåŠŸ")
            else:
                st.warning(f"âš  BERT æ¨¡å‹æœªæ‰¾åˆ°: {bert_path}")
        except Exception as e:
            st.warning(f"âš  æƒ…æ„Ÿåˆ†æå¼•æ“åŠ è½½å¤±è´¥: {e}")
        
        # 2. åŠ è½½ RAG å¼•æ“ï¼ˆEngine Bï¼‰
        try:
            rag_module_path = project_root / "app" / "core" / "engines" / "rag_engine.py"
            spec = importlib.util.spec_from_file_location("rag_engine", rag_module_path)
            rag_module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(rag_module)
            RagEngine = rag_module.RagEngine
            
            chroma_path = project_root / "data" / "reports" / "chroma_db"
            if chroma_path.exists():
                rag_engine = RagEngine(
                    chroma_path=str(chroma_path),
                    model_name="BAAI/bge-m3"
                )
                st.success("âœ“ RAG æ£€ç´¢å¼•æ“åŠ è½½æˆåŠŸ")
            else:
                st.warning(f"âš  Chroma å‘é‡åº“æœªæ‰¾åˆ°: {chroma_path}")
        except Exception as e:
            st.warning(f"âš  RAG å¼•æ“åŠ è½½å¤±è´¥: {e}")
        
        # 3. åŠ è½½è§„åˆ™å¼•æ“ï¼ˆå·²é›†æˆåœ¨ SentimentAnalyzer ä¸­ï¼‰
        # è§„åˆ™å¼•æ“ä¸éœ€è¦å•ç‹¬åŠ è½½
        
        # 4. åŠ è½½ LLM å®¢æˆ·ç«¯
        try:
            llm_module_path = project_root / "app" / "adapters" / "llm" / "deepseek_client.py"
            spec = importlib.util.spec_from_file_location("deepseek_client", llm_module_path)
            llm_module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(llm_module)
            DeepseekClient = llm_module.DeepseekClient
            
            if os.getenv("DEEPSEEK_API_KEY"):
                llm_client = DeepseekClient()
                st.success("âœ“ LLM å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            else:
                st.warning("âš  DEEPSEEK_API_KEY æœªé…ç½®")
        except Exception as e:
            st.warning(f"âš  LLM å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # 5. åˆ›å»º Agent
        db_path = project_root / "finance_analysis.db"
        agent = Agent(
            sentiment_engine=sentiment_engine,
            rag_engine=rag_engine,
            rule_engine=None,  # è§„åˆ™å¼•æ“å·²é›†æˆåœ¨ sentiment_engine ä¸­
            llm_client=llm_client,
            db_path=str(db_path)
        )
        
        return agent
    
    except Exception as e:
        st.error(f"åˆå§‹åŒ– Agent å¤±è´¥: {e}")
        import traceback
        st.error(traceback.format_exc())
        return None


def check_engine_status():
    """
    æ£€æŸ¥å¼•æ“çŠ¶æ€
    
    Returns:
        çŠ¶æ€å­—å…¸
    """
    import os
    
    status = {
        "sentiment_engine": False,
        "rag_engine": False,
        "llm_client": False
    }
    
    # æ£€æŸ¥ BERT æ¨¡å‹
    bert_path = project_root / "models" / "bert_3cls" / "best"
    if bert_path.exists():
        status["sentiment_engine"] = True
    
    # æ£€æŸ¥ Chroma å‘é‡åº“
    chroma_path = project_root / "data" / "reports" / "chroma_db"
    if chroma_path.exists():
        status["rag_engine"] = True
    
    # æ£€æŸ¥ Deepseek API Key
    if os.getenv("DEEPSEEK_API_KEY"):
        status["llm_client"] = True
    
    return status


def process_user_query(query: str, agent):
    """
    å¤„ç†ç”¨æˆ·æŸ¥è¯¢
    
    Args:
        query: ç”¨æˆ·æŸ¥è¯¢
        agent: Agent å®ä¾‹
    
    Returns:
        å“åº”å­—å…¸
    """
    if agent is None:
        return {
            "summary": "æŠ±æ­‰ï¼ŒAgent æœªåˆå§‹åŒ–ï¼Œæ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚ã€‚",
            "sentiment": None,
            "citations": [],
            "tool_trace": []
        }
    
    try:
        # è°ƒç”¨ Agent å¤„ç†
        answer = agent.process_query(query)
        
        # è½¬æ¢ä¸ºå­—å…¸
        response = {
            "summary": answer.summary,
            "sentiment": None,
            "citations": [],
            "tool_trace": []
        }
        
        # æ·»åŠ æƒ…æ„Ÿåˆ†æç»“æœ
        if answer.sentiment:
            from app.core.dto import sentiment_label_to_text
            label_text = sentiment_label_to_text(answer.sentiment.label)
            response["sentiment"] = f"{label_text}ï¼ˆç½®ä¿¡åº¦ {answer.sentiment.score:.2%}ï¼‰"
        
        # æ·»åŠ å¼•ç”¨
        if answer.citations:
            response["citations"] = [
                {
                    "text": c.text[:100] + "...",
                    "source": c.source_file,
                    "score": c.score
                }
                for c in answer.citations
            ]
        
        # æ·»åŠ å·¥å…·è¿½è¸ª
        if answer.tool_trace:
            response["tool_trace"] = [
                {
                    "name": t.name,
                    "elapsed_ms": t.elapsed_ms,
                    "ok": t.ok
                }
                for t in answer.tool_trace
            ]
        
        return response
    
    except Exception as e:
        return {
            "summary": f"å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {str(e)}",
            "sentiment": None,
            "citations": [],
            "tool_trace": []
        }


if __name__ == "__main__":
    main()
