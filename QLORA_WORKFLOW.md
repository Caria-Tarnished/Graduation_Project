# QLoRA å¾®è°ƒå·¥ä½œæµç¨‹

**æ›´æ–°æ—¶é—´**: 2026-02-09  
**ç›®æ ‡**: å¾®è°ƒ Deepseek-7B æ¨¡å‹ï¼Œæå‡è´¢ç»é¢†åŸŸä¸“ä¸šæ€§  
**ç¡¬ä»¶**: Google Colab T4 GPUï¼ˆå…è´¹ç‰ˆï¼‰  
**æ—¶é—´**: çº¦ 4-6 å°æ—¶ï¼ˆæ•°æ®å‡†å¤‡ + è®­ç»ƒ + æµ‹è¯•ï¼‰

---

## 1. å·¥ä½œæµç¨‹æ¦‚è§ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  é˜¶æ®µ 1: å‡†å¤‡æŒ‡ä»¤é›†æ•°æ®ï¼ˆ1-2 å°æ—¶ï¼‰                          â”‚
â”‚  - ä» finance_analysis.db æå–çœŸå®æ¡ˆä¾‹                      â”‚
â”‚  - ç”Ÿæˆ Instruction-Input-Output æ ¼å¼æ•°æ®                   â”‚
â”‚  - ç›®æ ‡ï¼š300 æ¡æŒ‡ä»¤ï¼ˆ60% æ–°é—» + 20% å¸‚åœºåˆ†æ + 20% è´¢æŠ¥ï¼‰   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  é˜¶æ®µ 2: Colab è®­ç»ƒï¼ˆ2-4 å°æ—¶ï¼‰                              â”‚
â”‚  - åŠ è½½ Deepseek-7B æ¨¡å‹ï¼ˆ4-bit é‡åŒ–ï¼‰                      â”‚
â”‚  - é…ç½® LoRAï¼ˆrank=8, alpha=16ï¼‰                            â”‚
â”‚  - è®­ç»ƒ 3 epochs                                            â”‚
â”‚  - ä¿å­˜ LoRA æƒé‡ï¼ˆçº¦ 30-50 MBï¼‰                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  é˜¶æ®µ 3: æµ‹è¯•ä¸é›†æˆï¼ˆ1 å°æ—¶ï¼‰                                â”‚
â”‚  - åœ¨ Colab ä¸Šæµ‹è¯•å¾®è°ƒæ•ˆæœ                                  â”‚
â”‚  - ä¸‹è½½ LoRA æƒé‡åˆ°æœ¬åœ°                                     â”‚
â”‚  - ï¼ˆå¯é€‰ï¼‰é›†æˆåˆ°æœ¬åœ° Agent ç³»ç»Ÿ                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. é˜¶æ®µ 1ï¼šå‡†å¤‡æŒ‡ä»¤é›†æ•°æ®

### 2.1 æœ¬åœ°ç”ŸæˆæŒ‡ä»¤é›†

åœ¨æœ¬åœ°è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š

```powershell
# ç”Ÿæˆ 300 æ¡æŒ‡ä»¤
python scripts/qlora/build_instruction_dataset.py `
    --db finance_analysis.db `
    --output data/qlora/instructions.jsonl `
    --num_samples 300
```

**è¾“å‡º**ï¼š
- æ–‡ä»¶ï¼š`data/qlora/instructions.jsonl`
- æ ¼å¼ï¼šæ¯è¡Œä¸€ä¸ª JSON å¯¹è±¡
- å¤§å°ï¼šçº¦ 100-200 KB

**æ•°æ®åˆ†å¸ƒ**ï¼š
- 60%ï¼ˆ180 æ¡ï¼‰ï¼šä»çœŸå®æ–°é—»ç”Ÿæˆï¼ˆåŸºäº finance_analysis.dbï¼‰
- 20%ï¼ˆ60 æ¡ï¼‰ï¼šå¸‚åœºåˆ†ææŒ‡ä»¤ï¼ˆé¢„æœŸå…‘ç°ã€è§‚æœ›ä¿¡å·ç­‰ï¼‰
- 20%ï¼ˆ60 æ¡ï¼‰ï¼šè´¢æŠ¥é—®ç­”æŒ‡ä»¤ï¼ˆæ¨¡æ‹Ÿï¼‰

### 2.2 æŸ¥çœ‹ç”Ÿæˆçš„æ•°æ®

```powershell
# æŸ¥çœ‹å‰ 3 æ¡æŒ‡ä»¤
python -c "import json; [print(f'\n{i+1}. {json.loads(line)}') for i, line in enumerate(open('data/qlora/instructions.jsonl', encoding='utf-8')) if i < 3]"
```

### 2.3 ä¸Šä¼ åˆ° GitHub

```powershell
git add data/qlora/instructions.jsonl
git commit -m "Add QLoRA instruction dataset"
git push
```

**æ³¨æ„**ï¼šç¡®ä¿ `.gitignore` å…è®¸æäº¤ `data/qlora/` ç›®å½•ã€‚

---

## 3. é˜¶æ®µ 2ï¼šColab è®­ç»ƒ

### 3.1 æ‰“å¼€ Colab ç¬”è®°æœ¬

1. è®¿é—® [Google Colab](https://colab.research.google.com/)
2. åˆ›å»ºæ–°ç¬”è®°æœ¬
3. é€‰æ‹©è¿è¡Œæ—¶ç±»å‹ï¼š**GPUï¼ˆT4ï¼‰**

### 3.2 å¤åˆ¶è®­ç»ƒå•å…ƒæ ¼

æ‰“å¼€ `colab_qlora_training_cells.txt`ï¼ŒæŒ‰é¡ºåºå¤åˆ¶å¹¶è¿è¡Œä»¥ä¸‹å•å…ƒæ ¼ï¼š

#### å•å…ƒæ ¼ 1ï¼šç¯å¢ƒå‡†å¤‡ï¼ˆçº¦ 5 åˆ†é’Ÿï¼‰
- æ£€æŸ¥ GPU
- æŒ‚è½½ Google Drive
- å®‰è£…ä¾èµ–ï¼ˆtransformers, peft, bitsandbytes ç­‰ï¼‰

#### å•å…ƒæ ¼ 2ï¼šå…‹éš†ä»£ç ä»“åº“ï¼ˆçº¦ 1 åˆ†é’Ÿï¼‰
- ä» GitHub å…‹éš†æˆ–æ›´æ–°ä»£ç 

#### å•å…ƒæ ¼ 3ï¼šç”ŸæˆæŒ‡ä»¤é›†ï¼ˆçº¦ 1 åˆ†é’Ÿï¼‰
- å¦‚æœæœ¬åœ°å·²ç”Ÿæˆï¼Œä¼šç›´æ¥ä½¿ç”¨
- å¦‚æœæœªç”Ÿæˆï¼Œä¼šåœ¨ Colab ä¸Šç”Ÿæˆ

#### å•å…ƒæ ¼ 4ï¼šå¼€å§‹è®­ç»ƒï¼ˆçº¦ 2-4 å°æ—¶ï¼‰â°
- åŠ è½½ Deepseek-7B æ¨¡å‹ï¼ˆ4-bit é‡åŒ–ï¼‰
- é…ç½® LoRA
- è®­ç»ƒ 3 epochs
- ä¿å­˜åˆ° Google Drive

**é‡è¦**ï¼š
- âš ï¸ ä¿æŒ Colab é¡µé¢æ‰“å¼€ï¼Œé¿å…æ–­å¼€è¿æ¥
- âš ï¸ å»ºè®®ä½¿ç”¨ Colab Proï¼ˆæ›´ç¨³å®šï¼‰
- âš ï¸ è®­ç»ƒè¿‡ç¨‹ä¸­å¯ä»¥æŸ¥çœ‹ Loss æ›²çº¿

#### å•å…ƒæ ¼ 5ï¼šéªŒè¯ç»“æœï¼ˆçº¦ 1 åˆ†é’Ÿï¼‰
- æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
- æŸ¥çœ‹è®­ç»ƒä¿¡æ¯
- ç¡®è®¤æƒé‡æ–‡ä»¶å¤§å°

#### å•å…ƒæ ¼ 6ï¼šæµ‹è¯•æ¨¡å‹ï¼ˆçº¦ 5 åˆ†é’Ÿï¼Œå¯é€‰ï¼‰
- åŠ è½½å¾®è°ƒåçš„æ¨¡å‹
- æµ‹è¯•æ¨ç†æ•ˆæœ
- å¯¹æ¯”å¾®è°ƒå‰åçš„è¾“å‡º

#### å•å…ƒæ ¼ 7ï¼šä¸‹è½½æƒé‡ï¼ˆå¯é€‰ï¼‰
- æ‰“åŒ… LoRA æƒé‡
- ä¸‹è½½åˆ°æœ¬åœ°ç”µè„‘

### 3.3 è®­ç»ƒå‚æ•°è¯´æ˜

| å‚æ•° | å€¼ | è¯´æ˜ |
|------|-----|------|
| `model_name` | deepseek-ai/deepseek-llm-7b-chat | åŸºç¡€æ¨¡å‹ |
| `num_epochs` | 3 | è®­ç»ƒè½®æ•° |
| `batch_size` | 4 | æ‰¹å¤§å° |
| `learning_rate` | 2e-4 | å­¦ä¹ ç‡ |
| `max_length` | 512 | æœ€å¤§åºåˆ—é•¿åº¦ |
| `lora_r` | 8 | LoRA rank |
| `lora_alpha` | 16 | LoRA alpha |
| `lora_dropout` | 0.05 | Dropout æ¯”ä¾‹ |

### 3.4 é¢„æœŸè¾“å‡º

è®­ç»ƒå®Œæˆåï¼Œåœ¨ Google Drive çš„ `Graduation_Project/qlora_output/` ç›®å½•ä¸‹ä¼šç”Ÿæˆï¼š

```
qlora_output/
â”œâ”€â”€ adapter_model.bin          # LoRA æƒé‡æ–‡ä»¶ï¼ˆçº¦ 30-50 MBï¼‰
â”œâ”€â”€ adapter_config.json        # LoRA é…ç½®æ–‡ä»¶
â”œâ”€â”€ training_info.json         # è®­ç»ƒä¿¡æ¯
â””â”€â”€ checkpoint-*/              # è®­ç»ƒ checkpointï¼ˆå¯é€‰ï¼‰
```

---

## 4. é˜¶æ®µ 3ï¼šæµ‹è¯•ä¸é›†æˆ

### 4.1 åœ¨ Colab ä¸Šæµ‹è¯•

è¿è¡Œå•å…ƒæ ¼ 6ï¼Œæµ‹è¯•å¾®è°ƒåçš„æ¨¡å‹ï¼š

```python
# æµ‹è¯•æ¡ˆä¾‹
test_cases = [
    {
        "instruction": "åˆ†æä»¥ä¸‹è´¢ç»å¿«è®¯å¯¹å¸‚åœºçš„å½±å“",
        "input": "ç¾è”å‚¨å®£å¸ƒåŠ æ¯25ä¸ªåŸºç‚¹"
    }
]

# æŸ¥çœ‹è¾“å‡º
# é¢„æœŸï¼šæ¨¡å‹ä¼šç”Ÿæˆä¸“ä¸šçš„è´¢ç»åˆ†æ
```

### 4.2 ä¸‹è½½æƒé‡åˆ°æœ¬åœ°

**æ–¹æ¡ˆ Aï¼šé€šè¿‡ Colab ä¸‹è½½**
- è¿è¡Œå•å…ƒæ ¼ 7
- ä¸‹è½½ `qlora_weights.zip`
- è§£å‹åˆ° `models/qlora/adapter/`

**æ–¹æ¡ˆ Bï¼šé€šè¿‡ Google Drive ä¸‹è½½**
- æ‰“å¼€ Google Drive
- æ‰¾åˆ° `Graduation_Project/qlora_output/`
- ä¸‹è½½ `adapter_model.bin` å’Œ `adapter_config.json`
- ä¿å­˜åˆ° `models/qlora/adapter/`

### 4.3 æœ¬åœ°æµ‹è¯•ï¼ˆå¯é€‰ï¼‰

```powershell
# æµ‹è¯•å¾®è°ƒåçš„æ¨¡å‹
python scripts/qlora/test_qlora_model.py `
    --adapter_path models/qlora/adapter `
    --test_cases "ç¾è”å‚¨å®£å¸ƒåŠ æ¯25ä¸ªåŸºç‚¹"
```

**æ³¨æ„**ï¼šæœ¬åœ°æµ‹è¯•éœ€è¦è¾ƒå¤§å†…å­˜ï¼ˆçº¦ 8GBï¼‰ï¼Œå¦‚æœç”µè„‘é…ç½®ä¸å¤Ÿï¼Œå¯ä»¥è·³è¿‡æ­¤æ­¥éª¤ã€‚

### 4.4 é›†æˆåˆ° Agentï¼ˆå¯é€‰ï¼‰

å¦‚æœè¦åœ¨æœ¬åœ° Agent ä¸­ä½¿ç”¨å¾®è°ƒåçš„æ¨¡å‹ï¼Œéœ€è¦ä¿®æ”¹ `app/adapters/llm/deepseek_client.py`ï¼š

```python
# æ–¹æ¡ˆ Aï¼šä½¿ç”¨ Colab éƒ¨ç½²çš„ APIï¼ˆæ¨èï¼‰
# åœ¨ Colab ä¸Šä½¿ç”¨ ngrok å¼€å¯ API æ¥å£
# æœ¬åœ°è°ƒç”¨è¯¥æ¥å£

# æ–¹æ¡ˆ Bï¼šæœ¬åœ°åŠ è½½ LoRA æƒé‡ï¼ˆéœ€è¦å¤§å†…å­˜ï¼‰
from peft import PeftModel

model = AutoModelForCausalLM.from_pretrained(
    "deepseek-ai/deepseek-llm-7b-chat",
    load_in_4bit=True,
    device_map='auto'
)
model = PeftModel.from_pretrained(model, "models/qlora/adapter")
```

**æ¨è**ï¼šç­”è¾©æ—¶ä½¿ç”¨ Deepseek APIï¼Œå±•ç¤º LoRA æƒé‡æ–‡ä»¶å’Œè®­ç»ƒæ—¥å¿—å³å¯ã€‚

---

## 5. ç­”è¾©å‡†å¤‡

### 5.1 éœ€è¦å‡†å¤‡çš„ææ–™

1. **è®­ç»ƒæ—¥å¿—æˆªå›¾**
   - Loss æ›²çº¿
   - è®­ç»ƒå‚æ•°
   - è®­ç»ƒæ—¶é—´

2. **LoRA æƒé‡æ–‡ä»¶**
   - `adapter_model.bin`ï¼ˆçº¦ 30-50 MBï¼‰
   - `adapter_config.json`
   - `training_info.json`

3. **æµ‹è¯•ç»“æœå¯¹æ¯”**
   - å¾®è°ƒå‰çš„è¾“å‡º
   - å¾®è°ƒåçš„è¾“å‡º
   - å¯¹æ¯”è¯´æ˜

### 5.2 ç­”è¾©è¯æœ¯

**é—®é¢˜ 1ï¼šä¸ºä»€ä¹ˆè¦åš QLoRA å¾®è°ƒï¼Ÿ**

> "é€šç”¨å¤§æ¨¡å‹è™½ç„¶èƒ½åŠ›å¼ºå¤§ï¼Œä½†åœ¨è´¢ç»é¢†åŸŸçš„ä¸“ä¸šæ€§ä¸è¶³ã€‚é€šè¿‡ QLoRA å¾®è°ƒï¼Œæˆ‘ä»¬å¯ä»¥ï¼š
> 1. è®©æ¨¡å‹å­¦ä¹ è´¢ç»é¢†åŸŸçš„ä¸“ä¸šæœ¯è¯­å’Œåˆ†ææ–¹æ³•
> 2. æå‡æ¨¡å‹å¯¹å¸‚åœºèµ°åŠ¿çš„ç†è§£èƒ½åŠ›
> 3. ä½¿æ¨¡å‹è¾“å‡ºæ›´ç¬¦åˆè´¢ç»åˆ†æå¸ˆçš„è¡¨è¾¾ä¹ æƒ¯"

**é—®é¢˜ 2ï¼šä¸ºä»€ä¹ˆä½¿ç”¨ QLoRA è€Œä¸æ˜¯å®Œæ•´å¾®è°ƒï¼Ÿ**

> "QLoRA æ˜¯ä¸€ç§å‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•ï¼Œç›¸æ¯”å®Œæ•´å¾®è°ƒæœ‰ä»¥ä¸‹ä¼˜åŠ¿ï¼š
> 1. æ˜¾å­˜å ç”¨ä½ï¼š4-bit é‡åŒ– + LoRAï¼ŒT4 GPU å³å¯è®­ç»ƒ 7B æ¨¡å‹
> 2. è®­ç»ƒé€Ÿåº¦å¿«ï¼šåªè®­ç»ƒçº¦ 0.1% çš„å‚æ•°ï¼Œè®­ç»ƒæ—¶é—´å¤§å¹…ç¼©çŸ­
> 3. æƒé‡æ–‡ä»¶å°ï¼šLoRA æƒé‡ä»… 30-50 MBï¼Œä¾¿äºå­˜å‚¨å’Œéƒ¨ç½²"

**é—®é¢˜ 3ï¼šä¸ºä»€ä¹ˆç­”è¾©æ—¶ä½¿ç”¨ API è€Œä¸æ˜¯æœ¬åœ°æ¨¡å‹ï¼Ÿ**

> "è€ƒè™‘åˆ°æ¼”ç¤ºæµç•…åº¦å’Œç¡¬ä»¶é™åˆ¶ï¼š
> 1. æœ¬åœ°æ˜¾å­˜ä¸è¶³ï¼ˆMX570 2GBï¼‰ï¼Œæ— æ³•åŠ è½½ 7B æ¨¡å‹
> 2. ä½¿ç”¨ API å¯ä»¥ä¿è¯æ¨ç†é€Ÿåº¦å’Œç¨³å®šæ€§
> 3. æˆ‘å·²ç»å®Œæˆäº†å¾®è°ƒå·¥ä½œï¼ˆå±•ç¤ºè®­ç»ƒæ—¥å¿—å’Œæƒé‡æ–‡ä»¶ï¼‰
> 4. å®é™…éƒ¨ç½²æ—¶å¯ä»¥åœ¨äº‘ç«¯æœåŠ¡å™¨ä¸ŠåŠ è½½å¾®è°ƒåçš„æ¨¡å‹"

**é—®é¢˜ 4ï¼šå¾®è°ƒæ•ˆæœå¦‚ä½•è¯„ä¼°ï¼Ÿ**

> "æˆ‘ä»¬é€šè¿‡ä»¥ä¸‹æ–¹å¼è¯„ä¼°å¾®è°ƒæ•ˆæœï¼š
> 1. å®šæ€§è¯„ä¼°ï¼šå¯¹æ¯”å¾®è°ƒå‰åçš„è¾“å‡ºè´¨é‡
> 2. äººå·¥è¯„ä¼°ï¼šé‚€è¯·è´¢ç»ä¸“ä¸šäººå£«è¯„ä¼°è¾“å‡ºçš„ä¸“ä¸šæ€§
> 3. å®é™…åº”ç”¨ï¼šåœ¨ Agent ç³»ç»Ÿä¸­æµ‹è¯•ï¼Œè§‚å¯Ÿç”¨æˆ·åé¦ˆ"

---

## 6. å¸¸è§é—®é¢˜

### Q1: è®­ç»ƒè¿‡ç¨‹ä¸­æ–­å¼€è¿æ¥æ€ä¹ˆåŠï¼Ÿ

**A**: è®­ç»ƒä¼šè‡ªåŠ¨ä¿å­˜ checkpointï¼Œå¯ä»¥ä»æœ€è¿‘çš„ checkpoint ç»§ç»­è®­ç»ƒï¼š

```python
# åœ¨è®­ç»ƒå‘½ä»¤ä¸­æ·»åŠ  --resume_from_checkpoint
!python scripts/qlora/train_qlora.py \
    --resume_from_checkpoint /content/drive/MyDrive/Graduation_Project/qlora_output/checkpoint-100 \
    ...
```

### Q2: æ˜¾å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ

**A**: å‡å°æ‰¹å¤§å°æˆ–åºåˆ—é•¿åº¦ï¼š

```python
# å‡å°æ‰¹å¤§å°
--batch_size 2

# å‡å°åºåˆ—é•¿åº¦
--max_length 256
```

### Q3: å¦‚ä½•è¯„ä¼°å¾®è°ƒæ•ˆæœï¼Ÿ

**A**: 
1. è¿è¡Œå•å…ƒæ ¼ 6ï¼Œæµ‹è¯•æ¨¡å‹è¾“å‡º
2. å¯¹æ¯”å¾®è°ƒå‰åçš„è¾“å‡ºè´¨é‡
3. ä½¿ç”¨äººå·¥è¯„ä¼°ï¼ˆé‚€è¯·è´¢ç»ä¸“ä¸šäººå£«ï¼‰

### Q4: å¦‚ä½•åœ¨æœ¬åœ°ä½¿ç”¨å¾®è°ƒåçš„æ¨¡å‹ï¼Ÿ

**A**: 
1. ä¸‹è½½ LoRA æƒé‡æ–‡ä»¶
2. ä½¿ç”¨ PEFT åº“åŠ è½½ï¼ˆå‚è€ƒ `test_qlora_model.py`ï¼‰
3. æ³¨æ„ï¼šéœ€è¦è¾ƒå¤§å†…å­˜ï¼ˆçº¦ 8GBï¼‰

### Q5: è®­ç»ƒæ•°æ®ä¸å¤Ÿæ€ä¹ˆåŠï¼Ÿ

**A**: 
1. å¢åŠ æ•°æ®ç”Ÿæˆè„šæœ¬ä¸­çš„æ ·æœ¬æ•°é‡
2. ä½¿ç”¨ GPT-4 æˆ– Kimi ç”Ÿæˆæ›´å¤šæŒ‡ä»¤
3. ä»å…¶ä»–æ•°æ®æºï¼ˆå¦‚è´¢ç»æ–°é—»ç½‘ç«™ï¼‰çˆ¬å–æ•°æ®

---

## 7. æ—¶é—´è§„åˆ’

| é˜¶æ®µ | ä»»åŠ¡ | é¢„è®¡æ—¶é—´ |
|------|------|----------|
| é˜¶æ®µ 1 | å‡†å¤‡æŒ‡ä»¤é›†æ•°æ® | 1-2 å°æ—¶ |
| é˜¶æ®µ 2 | Colab è®­ç»ƒ | 2-4 å°æ—¶ |
| é˜¶æ®µ 3 | æµ‹è¯•ä¸é›†æˆ | 1 å°æ—¶ |
| **æ€»è®¡** | | **4-7 å°æ—¶** |

**å»ºè®®**ï¼š
- ç¬¬ 1 å¤©ï¼šå®Œæˆé˜¶æ®µ 1ï¼ˆæ•°æ®å‡†å¤‡ï¼‰
- ç¬¬ 2 å¤©ï¼šå®Œæˆé˜¶æ®µ 2ï¼ˆColab è®­ç»ƒï¼‰
- ç¬¬ 3 å¤©ï¼šå®Œæˆé˜¶æ®µ 3ï¼ˆæµ‹è¯•ä¸é›†æˆï¼‰

---

## 8. ä¸‹ä¸€æ­¥

å®Œæˆ QLoRA å¾®è°ƒåï¼š

1. **æ›´æ–° Project_Status.md**
   - è®°å½• QLoRA å¾®è°ƒå®Œæˆ
   - æ·»åŠ è®­ç»ƒå‚æ•°å’Œç»“æœ

2. **å‡†å¤‡ç­”è¾©ææ–™**
   - æˆªå›¾è®­ç»ƒæ—¥å¿—
   - å‡†å¤‡å¯¹æ¯”æµ‹è¯•ç»“æœ
   - æ•´ç†ç­”è¾©è¯æœ¯

3. **å¯é€‰ï¼šé›†æˆåˆ° Agent**
   - åœ¨ Colab ä¸Šéƒ¨ç½² API
   - æœ¬åœ°è°ƒç”¨å¾®è°ƒåçš„æ¨¡å‹

---

**ç¥è®­ç»ƒé¡ºåˆ©ï¼** ğŸ“


---

## 9. å¸¸è§é—®é¢˜ä¿®å¤ï¼ˆ2026-02-10 æ›´æ–°ï¼‰

### é—®é¢˜ 1ï¼štriton ç‰ˆæœ¬ä¸å¯ç”¨

**é”™è¯¯ä¿¡æ¯**ï¼š
```
ERROR: Could not find a version that satisfies the requirement triton==2.1.0
```

**åŸå› **ï¼šColab ç¯å¢ƒåªæä¾› triton 2.2.0 åŠä»¥ä¸Šç‰ˆæœ¬

**è§£å†³æ–¹æ¡ˆ**ï¼ˆå·²åœ¨ colab_qlora_training_cells_final.txt ä¸­ä¿®å¤ï¼‰ï¼š
```python
# ä½¿ç”¨ Colab å¯ç”¨çš„æœ€ä½ç‰ˆæœ¬
!pip install -q triton==2.2.0
!pip install -q bitsandbytes==0.43.3  # å…¼å®¹ triton 2.2.0
```

### é—®é¢˜ 2ï¼šæ•°æ®åº“åˆ—åé”™è¯¯

**é”™è¯¯ä¿¡æ¯**ï¼š
```
âœ— æå–æ–°é—»æ ·æœ¬å¤±è´¥: no such column: ei.ret_post_15m
```

**åŸå› **ï¼šæ•°æ®åº“å®é™…ç»“æ„ä¸ä»£ç å‡è®¾ä¸åŒ¹é…

**æ•°æ®åº“å®é™…ç»“æ„**ï¼š
```sql
-- event_impacts è¡¨ç»“æ„
CREATE TABLE event_impacts (
    event_id TEXT NOT NULL,
    ticker TEXT NOT NULL,
    window_min INTEGER NOT NULL,  -- æ—¶é—´çª—å£ï¼ˆ5/10/15/30/120 åˆ†é’Ÿï¼‰
    ret REAL,                      -- æ”¶ç›Šç‡
    ...
    PRIMARY KEY (event_id, ticker, window_min)
);
```

**æ­£ç¡®çš„æŸ¥è¯¢æ–¹å¼**ï¼š
```sql
-- ä½¿ç”¨ window_min åŒºåˆ†ä¸åŒæ—¶é—´çª—å£
SELECT 
    e.content,
    e.star,
    ei_post.ret as ret_post,      -- 15 åˆ†é’Ÿåæ”¶ç›Š
    ei_pre.ret as ret_pre          -- 120 åˆ†é’Ÿå‰æ”¶ç›Š
FROM events e
LEFT JOIN event_impacts ei_post ON e.event_id = ei_post.event_id AND ei_post.window_min = 15
LEFT JOIN event_impacts ei_pre ON e.event_id = ei_pre.event_id AND ei_pre.window_min = 120
```

**è§£å†³æ–¹æ¡ˆ**ï¼ˆå·²åœ¨ scripts/qlora/build_instruction_dataset.py ä¸­ä¿®å¤ï¼‰ï¼š
- ä½¿ç”¨æ­£ç¡®çš„è¡¨ç»“æ„å’Œåˆ—å
- é€šè¿‡ `window_min` ç­›é€‰ä¸åŒæ—¶é—´çª—å£
- ç§»é™¤ Colab ä¸­çš„åˆ—åæ›¿æ¢é€»è¾‘ï¼ˆä¸å†éœ€è¦ï¼‰

### é—®é¢˜ 3ï¼šbitsandbytes CUDA æ”¯æŒç¼ºå¤±

**é”™è¯¯ä¿¡æ¯**ï¼š
```
WARNING: The installed version of bitsandbytes was compiled without GPU support
ModuleNotFoundError: No module named 'triton.ops'
```

**åŸå› **ï¼šä¾èµ–ç‰ˆæœ¬ä¸å…¼å®¹

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. ç¡®ä¿æŒ‰é¡ºåºå®‰è£…ä¾èµ–ï¼ˆå…ˆ tritonï¼Œå bitsandbytesï¼‰
2. ä½¿ç”¨å…¼å®¹çš„ç‰ˆæœ¬ç»„åˆï¼š
   - triton==2.2.0
   - bitsandbytes==0.43.3
   - transformers==4.46.0

### é—®é¢˜ 4ï¼šfsspec ç‰ˆæœ¬å†²çªè­¦å‘Š

**è­¦å‘Šä¿¡æ¯**ï¼š
```
gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.6.1
```

**å½±å“**ï¼šä¸å½±å“è®­ç»ƒï¼Œå¯ä»¥å¿½ç•¥

**å¯é€‰è§£å†³**ï¼š
```python
!pip install -q fsspec==2025.3.0
```

### æœ€æ–°ä¿®å¤ç‰ˆæœ¬

ä½¿ç”¨æ–‡ä»¶ï¼š`colab_qlora_training_cells_final.txt`

**å…³é”®ä¿®å¤ç‚¹**ï¼š
1. âœ… triton ç‰ˆæœ¬ï¼š2.1.0 â†’ 2.2.0
2. âœ… bitsandbytes ç‰ˆæœ¬ï¼š0.43.1 â†’ 0.43.3
3. âœ… æ•°æ®åº“åˆ—åæ›¿æ¢ï¼šæ·»åŠ é‡å¤æ£€æŸ¥
4. âœ… ä¾èµ–å®‰è£…é¡ºåºï¼šå…ˆå¸è½½æ—§ç‰ˆæœ¬ï¼Œå†æŒ‰é¡ºåºå®‰è£…

**éªŒè¯æˆåŠŸæ ‡å¿—**ï¼š
```
âœ“ ç¯å¢ƒå‡†å¤‡å®Œæˆ
âœ“ ä¾èµ–ç‰ˆæœ¬ï¼š
Name: bitsandbytes
Version: 0.43.3
Name: triton
Version: 2.2.0
```

### å¦‚æœä»ç„¶é‡åˆ°é—®é¢˜

1. **é‡å¯ Colab Runtime**
   - ç‚¹å‡»"è¿è¡Œæ—¶" â†’ "é‡å¯è¿è¡Œæ—¶"
   - é‡æ–°æ‰§è¡Œæ‰€æœ‰å•å…ƒæ ¼

2. **æ£€æŸ¥ GPU å¯ç”¨æ€§**
   ```python
   !nvidia-smi
   ```

3. **æ‰‹åŠ¨å®‰è£…ä¾èµ–**
   ```python
   !pip uninstall -y bitsandbytes triton -q
   !pip install triton==2.2.0 -q
   !pip install bitsandbytes==0.43.3 -q
   ```

4. **ä½¿ç”¨æ¨¡æ¿æ•°æ®è®­ç»ƒ**
   - å¦‚æœæ•°æ®åº“é—®é¢˜æ— æ³•è§£å†³
   - åˆ é™¤æˆ–é‡å‘½å `finance_analysis.db`
   - è„šæœ¬ä¼šè‡ªåŠ¨ä½¿ç”¨æ¨¡æ¿æ•°æ®ï¼ˆ120æ¡æŒ‡ä»¤ï¼‰
